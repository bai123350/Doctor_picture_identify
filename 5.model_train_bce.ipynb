{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8cd8995-9649-480e-8446-3b535235e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据\n",
    "# 1.导入unet模型\n",
    "# 2.自定义dice loss函数、\n",
    "# 3.开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24124740-fea2-41cb-8789-93a76d6187d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\envs\\course_unet_seg\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "# 数据增强相关包\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b11bb627-c849-4e43-846c-9939e385a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentDataset(Dataset):\n",
    "    def __init__(self,where='train',seq=None):\n",
    "        # 获取numpy文件数据\n",
    "        # 图片列表\n",
    "        self.img_list = glob.glob('processed/{}/*/img_*'.format(where))\n",
    "        # self.mask_list = glob.glob('processed/{}/*/label_*'.format(where))\n",
    "        # 数据增强的处理流程\n",
    "        self.seq = seq\n",
    "        \n",
    "    def __len__(self):\n",
    "        # 获取数据集大小\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        # 获取具体某一个数据\n",
    "        \n",
    "        # 获取图片文件名\n",
    "        img_file = self.img_list[idx]\n",
    "        # 获取标注文件名\n",
    "        mask_file = img_file.replace('img','label')\n",
    "        \n",
    "        # 加载数据\n",
    "        img = np.load(img_file)\n",
    "        mask = np.load(mask_file)\n",
    "        \n",
    "        # 数据增强处理\n",
    "        if self.seq:\n",
    "            segmap = SegmentationMapsOnImage(mask,shape=mask.shape)\n",
    "            img,mask = self.seq(image=img, segmentation_maps=segmap)\n",
    "            # 获取数组内容\n",
    "            mask = mask.get_arr()\n",
    "\n",
    "            \n",
    "        # 扩张维度变成张量\n",
    "        return np.expand_dims(img,0),np.expand_dims(mask,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea901971-8693-4cf7-9b68-e98ac447d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据增强的处理流程\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Affine(\n",
    "        scale=(0.8,1.2), # 缩放\n",
    "        rotate=(-45,45) # 旋转\n",
    "    ),\n",
    "    iaa.ElasticTransformation() # 弹性形变\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea78071e-0e7b-4f9e-88f3-1d8168d23011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用dataloader加载数据\n",
    "batch_size = 12\n",
    "num_workers = 0\n",
    "\n",
    "train_dataset = SegmentDataset('train',seq)\n",
    "test_dataset = SegmentDataset('test',None)\n",
    "\n",
    "# dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,num_workers=num_workers,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size,num_workers=num_workers,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1769aa-232a-4a77-8f2b-40ab2a03f3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aa5664c-e971-453c-8a54-70b428c298e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入unet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0048cae-5d55-4794-95d0-894f402cb825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义两次卷积操作\n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.step = torch.nn.Sequential(\n",
    "            # 第一次卷积\n",
    "            torch.nn.Conv2d(in_channels=in_channels,out_channels=out_channels,kernel_size=3,padding=1,stride=1),\n",
    "            # ReLU\n",
    "            torch.nn.ReLU(),\n",
    "            # 第二次卷积\n",
    "            torch.nn.Conv2d(in_channels=out_channels,out_channels=out_channels,kernel_size=3,padding=1,stride=1),\n",
    "            # ReLU\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        return self.step(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c03d8e6-d1ab-4b0c-ab29-a7f9c0cd374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 定义左侧编码器的操作\n",
    "        self.layer1 = ConvBlock(1,64)\n",
    "        self.layer2 = ConvBlock(64,128)\n",
    "        self.layer3 = ConvBlock(128,256)\n",
    "        self.layer4 = ConvBlock(256,512)\n",
    "        \n",
    "        # 定义右侧解码器的操作\n",
    "        self.layer5 = ConvBlock(256+512,256)\n",
    "        self.layer6 = ConvBlock(128+256,128)\n",
    "        self.layer7 = ConvBlock(64+128,64)\n",
    "        \n",
    "        #最后一个卷积\n",
    "        self.layer8  = torch.nn.Conv2d(in_channels=64,out_channels=1,kernel_size=1,padding=0,stride=1)\n",
    "        \n",
    "        # 定一些其他操作\n",
    "        # 池化\n",
    "        self.maxpool = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        #上采样\n",
    "        self.upsample = torch.nn.Upsample(scale_factor=2,mode='bilinear')\n",
    "        # sigmoid\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # 对输入数据进行处理\n",
    "        \n",
    "        # 定义下采样部分\n",
    "        \n",
    "        # input:1X256x256, output: 64x256x256\n",
    "        x1 = self.layer1(x)\n",
    "        # input:64x256x256, output: 64 x 128 x 128\n",
    "        x1_p = self.maxpool(x1)\n",
    "        \n",
    "        # input:  64 x 128 x 128 , output: 128 x 128 x 128\n",
    "        x2 = self.layer2(x1_p)\n",
    "        # input:128 x 128 x 128 , output: 128 x 64 x 64\n",
    "        x2_p = self.maxpool(x2)\n",
    "        \n",
    "        # input: 128 x 64 x 64, output: 256 x 64 x 64\n",
    "        x3 = self.layer3(x2_p)\n",
    "        #input:256 x 64 x 64, output: 256 x 32 x 32\n",
    "        x3_p = self.maxpool(x3)\n",
    "        \n",
    "        #input: 256 x 32 x 32, output: 512 x 32 x 32\n",
    "        x4 = self.layer4(x3_p)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 定义上采样\n",
    "        # input: 512 x 32 x 32，output: 512 x 64 x 64\n",
    "        x5 = self.upsample(x4)\n",
    "        # 拼接,output: 768x 64 x 64\n",
    "        x5 = torch.cat([x5,x3],dim=1)\n",
    "        # input: 768x 64 x 64,output: 256 x 64 x 64\n",
    "        x5 = self.layer5(x5)\n",
    "        \n",
    "        # input: 256 x 64 x 64,output: 256 x 128 x 128\n",
    "        x6  = self.upsample(x5)\n",
    "        # 拼接,output: 384 x 128 x 128\n",
    "        x6 = torch.cat([x6,x2],dim=1)\n",
    "        # input: 384 x 128 x 128, output: 128 x 128 x 128\n",
    "        x6 = self.layer6(x6)\n",
    "        \n",
    "        \n",
    "        # input:128 x 128 x 128, output: 128 x 256 x 256\n",
    "        x7 = self.upsample(x6)\n",
    "        # 拼接, output: 192 x 256 x256\n",
    "        x7 = torch.cat([x7,x1],dim=1)\n",
    "        # input: 192 x 256 x256, output: 64 x 256 x 256\n",
    "        x7 = self.layer7(x7)\n",
    "        \n",
    "        # 最后一次卷积,input: 64 x 256 x 256, output: 1 x 256 x 256\n",
    "        x8 = self.layer8(x7)\n",
    "        \n",
    "        #sigmoid\n",
    "        # x9= self.sigmoid(x8)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return x8\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4d422e5-2e7d-4141-a774-119357a3e0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ec86373-caf2-4455-9ea4-1ccb8f07cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87cd7e77-e51b-49ac-a5af-d50fa5e2c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "720057de-35f4-4c54-acb8-c0e7b0e8f947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "738df999-7c07-44d9-99d8-862afebe84b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型实例化\n",
    "model = UNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e2081a4-8e68-4cf5-a2c2-ba22a543e644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]             640\n",
      "              ReLU-2         [-1, 64, 256, 256]               0\n",
      "            Conv2d-3         [-1, 64, 256, 256]          36,928\n",
      "              ReLU-4         [-1, 64, 256, 256]               0\n",
      "         ConvBlock-5         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-6         [-1, 64, 128, 128]               0\n",
      "            Conv2d-7        [-1, 128, 128, 128]          73,856\n",
      "              ReLU-8        [-1, 128, 128, 128]               0\n",
      "            Conv2d-9        [-1, 128, 128, 128]         147,584\n",
      "             ReLU-10        [-1, 128, 128, 128]               0\n",
      "        ConvBlock-11        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-12          [-1, 128, 64, 64]               0\n",
      "           Conv2d-13          [-1, 256, 64, 64]         295,168\n",
      "             ReLU-14          [-1, 256, 64, 64]               0\n",
      "           Conv2d-15          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-16          [-1, 256, 64, 64]               0\n",
      "        ConvBlock-17          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-18          [-1, 256, 32, 32]               0\n",
      "           Conv2d-19          [-1, 512, 32, 32]       1,180,160\n",
      "             ReLU-20          [-1, 512, 32, 32]               0\n",
      "           Conv2d-21          [-1, 512, 32, 32]       2,359,808\n",
      "             ReLU-22          [-1, 512, 32, 32]               0\n",
      "        ConvBlock-23          [-1, 512, 32, 32]               0\n",
      "         Upsample-24          [-1, 512, 64, 64]               0\n",
      "           Conv2d-25          [-1, 256, 64, 64]       1,769,728\n",
      "             ReLU-26          [-1, 256, 64, 64]               0\n",
      "           Conv2d-27          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-28          [-1, 256, 64, 64]               0\n",
      "        ConvBlock-29          [-1, 256, 64, 64]               0\n",
      "         Upsample-30        [-1, 256, 128, 128]               0\n",
      "           Conv2d-31        [-1, 128, 128, 128]         442,496\n",
      "             ReLU-32        [-1, 128, 128, 128]               0\n",
      "           Conv2d-33        [-1, 128, 128, 128]         147,584\n",
      "             ReLU-34        [-1, 128, 128, 128]               0\n",
      "        ConvBlock-35        [-1, 128, 128, 128]               0\n",
      "         Upsample-36        [-1, 128, 256, 256]               0\n",
      "           Conv2d-37         [-1, 64, 256, 256]         110,656\n",
      "             ReLU-38         [-1, 64, 256, 256]               0\n",
      "           Conv2d-39         [-1, 64, 256, 256]          36,928\n",
      "             ReLU-40         [-1, 64, 256, 256]               0\n",
      "        ConvBlock-41         [-1, 64, 256, 256]               0\n",
      "           Conv2d-42          [-1, 1, 256, 256]              65\n",
      "          Sigmoid-43          [-1, 1, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 7,781,761\n",
      "Trainable params: 7,781,761\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 707.00\n",
      "Params size (MB): 29.69\n",
      "Estimated Total Size (MB): 736.94\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\envs\\course_unet_seg\\lib\\site-packages\\torch\\nn\\functional.py:3454: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "summary(model,(1,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15279f4e-1213-4935-9d89-c4ab23cc0110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟输入输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ffe373a-36f6-4877-9405-cc4f6c234339",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = torch.randn((1,1,256,256)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28f53d50-e0bc-425e-b842-ddf94dd87044",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(random_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1238608-4e26-44db-a1b2-cfbdfe0fb5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4702, 0.4719, 0.4711,  ..., 0.4712, 0.4723, 0.4720],\n",
       "          [0.4734, 0.4704, 0.4706,  ..., 0.4719, 0.4727, 0.4727],\n",
       "          [0.4712, 0.4747, 0.4716,  ..., 0.4729, 0.4725, 0.4727],\n",
       "          ...,\n",
       "          [0.4717, 0.4717, 0.4710,  ..., 0.4724, 0.4726, 0.4716],\n",
       "          [0.4708, 0.4731, 0.4731,  ..., 0.4715, 0.4735, 0.4722],\n",
       "          [0.4720, 0.4708, 0.4728,  ..., 0.4712, 0.4742, 0.4733]]]],\n",
       "       device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70725eb4-85c2-47d3-b282-66f639326992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae26a6c-9e79-4cfa-a35d-8707fc1cb035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368eea4-3c66-4100-9fa5-ab79c8409860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27999462-7edc-4ffa-97a5-b60a078bf57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcc95187-d7a3-4155-a614-1514c734000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义 loss 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fba3e4c-27fb-4085-b7ae-1f4cb1d5016e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aba15d82-0ee0-452f-a922-94ea4ac092b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2e9f523-8c89-4bc3-8855-595736b18474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dec2d93-517f-4a82-9ebb-243ecc147fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "843eea19-53fc-4e69-b2c0-c6d1b465613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 动态减少学习率\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8f7fba1-b075-4714-b925-63396c21618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ReduceLROnPlateau(optimizer,'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b8201b5-6bd5-4115-b402-248b853aed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用tensorboard可视化\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56de6dd2-2457-408b-a003-9c3eff8f0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir='./log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c336e73-e1c3-41a9-a553-ecfe022e0468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5fbaf9a-b76c-4060-9d4b-a29554708eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7dc73ef5-7a67-420d-9a69-8b75a9d007a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算测试集的loss\n",
    "def check_test_loss(loader,model):\n",
    "    # 记录loss\n",
    "    loss = 0\n",
    "    # 不记录梯度\n",
    "    with torch.no_grad():\n",
    "        # 遍历测试数据\n",
    "        for i,(x,y) in enumerate(loader):\n",
    "            # 获取图像\n",
    "            x = x.to(device,dtype=torch.float32)\n",
    "            # 获取标注\n",
    "            y = y.to(device,dtype=torch.float32)\n",
    "\n",
    "            # 获取预测值\n",
    "            y_pred = model(x)\n",
    "\n",
    "            # 计算loss\n",
    "            loss_batch = loss_fn(y_pred,y)\n",
    "            \n",
    "            # 累加\n",
    "            loss += loss_batch\n",
    "    \n",
    "    loss = loss/len(loader)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0f1555e-5fa0-4b8f-8557-056a6241054d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9859)\n",
      "tensor(0.9841)\n",
      "tensor(0.9859)\n",
      "tensor(0.9926)\n",
      "tensor(0.9858)\n",
      "tensor(0.9898)\n",
      "tensor(0.9887)\n",
      "tensor(0.9870)\n",
      "tensor(0.9915)\n",
      "tensor(0.9911)\n",
      "tensor(0.9925)\n",
      "tensor(0.9797)\n",
      "tensor(0.9925)\n",
      "tensor(0.9906)\n",
      "tensor(0.9862)\n",
      "tensor(0.9817)\n",
      "tensor(0.9799)\n",
      "tensor(0.9791)\n",
      "tensor(0.9833)\n",
      "tensor(0.9936)\n",
      "tensor(0.9817)\n",
      "tensor(0.9885)\n",
      "tensor(0.9875)\n",
      "tensor(0.9790)\n",
      "tensor(0.9951)\n",
      "tensor(0.9841)\n",
      "tensor(0.9628)\n",
      "tensor(0.9142)\n",
      "tensor(0.7962)\n",
      "tensor(0.7979)\n",
      "tensor(0.8303)\n",
      "tensor(0.7448)\n",
      "tensor(0.7398)\n",
      "tensor(0.9175)\n",
      "tensor(0.7898)\n",
      "tensor(0.9971)\n",
      "tensor(0.6858)\n",
      "tensor(0.7681)\n",
      "tensor(0.7243)\n",
      "tensor(0.6306)\n",
      "tensor(0.6135)\n",
      "tensor(0.6614)\n",
      "tensor(0.7772)\n",
      "tensor(0.5373)\n",
      "tensor(0.6541)\n",
      "tensor(0.4955)\n",
      "tensor(0.6770)\n",
      "tensor(0.7131)\n",
      "tensor(0.6002)\n",
      "tensor(0.5722)\n",
      "tensor(0.5872)\n",
      "tensor(0.5619)\n",
      "tensor(0.5302)\n",
      "tensor(0.6186)\n",
      "tensor(0.5945)\n",
      "tensor(0.6427)\n",
      "tensor(0.5634)\n",
      "tensor(0.6602)\n",
      "tensor(0.5104)\n",
      "tensor(0.6638)\n",
      "tensor(0.6217)\n",
      "tensor(0.6387)\n",
      "tensor(0.4631)\n",
      "tensor(0.5970)\n",
      "tensor(0.6890)\n",
      "tensor(0.6843)\n",
      "tensor(0.5185)\n",
      "tensor(0.5051)\n",
      "tensor(0.6323)\n",
      "tensor(0.6826)\n",
      "tensor(0.7763)\n",
      "tensor(0.5851)\n",
      "tensor(0.7378)\n",
      "tensor(0.6243)\n",
      "tensor(0.5830)\n",
      "tensor(0.5679)\n",
      "tensor(0.5585)\n",
      "tensor(0.5610)\n",
      "tensor(0.9230)\n",
      "tensor(0.7094)\n",
      "tensor(0.5786)\n",
      "tensor(0.4961)\n",
      "tensor(0.7290)\n",
      "tensor(0.7750)\n",
      "tensor(0.6920)\n",
      "tensor(0.5902)\n",
      "tensor(0.5071)\n",
      "tensor(0.5776)\n",
      "tensor(0.7610)\n",
      "tensor(0.7653)\n",
      "tensor(0.6661)\n",
      "tensor(0.4112)\n",
      "tensor(0.5231)\n",
      "tensor(0.5602)\n",
      "tensor(0.5632)\n",
      "tensor(0.5567)\n",
      "tensor(0.5871)\n",
      "tensor(0.5974)\n",
      "tensor(0.4778)\n",
      "tensor(0.5327)\n",
      "tensor(0.4342)\n",
      "tensor(0.5178)\n",
      "tensor(0.4712)\n",
      "tensor(0.4611)\n",
      "tensor(0.5665)\n",
      "tensor(0.5770)\n",
      "tensor(0.5835)\n",
      "tensor(0.4424)\n",
      "tensor(0.7338)\n",
      "tensor(0.4479)\n",
      "tensor(0.6409)\n",
      "tensor(0.5465)\n",
      "tensor(0.7161)\n",
      "tensor(0.5725)\n",
      "tensor(0.7001)\n",
      "tensor(0.6404)\n",
      "tensor(0.5990)\n",
      "tensor(0.5024)\n",
      "tensor(0.6132)\n",
      "tensor(0.6025)\n",
      "tensor(0.5655)\n",
      "tensor(0.5899)\n",
      "tensor(0.5216)\n",
      "tensor(0.5082)\n",
      "tensor(0.5480)\n",
      "tensor(0.5158)\n",
      "tensor(0.4934)\n",
      "tensor(0.5369)\n",
      "tensor(0.5687)\n",
      "tensor(0.5218)\n",
      "tensor(0.5286)\n",
      "tensor(0.4085)\n",
      "tensor(0.5290)\n",
      "tensor(0.4881)\n",
      "tensor(0.5375)\n",
      "tensor(0.4641)\n",
      "tensor(0.4937)\n",
      "tensor(0.5654)\n",
      "tensor(0.4087)\n",
      "tensor(0.4878)\n",
      "tensor(0.6581)\n",
      "tensor(0.7077)\n",
      "tensor(0.5366)\n",
      "tensor(0.4966)\n",
      "tensor(0.5208)\n",
      "tensor(0.4194)\n",
      "tensor(0.5095)\n",
      "tensor(0.7018)\n",
      "tensor(0.3070)\n",
      "tensor(0.4347)\n",
      "tensor(0.5252)\n",
      "tensor(0.6197)\n",
      "tensor(0.6125)\n",
      "tensor(0.4501)\n",
      "tensor(0.5684)\n",
      "tensor(0.5093)\n",
      "tensor(0.6277)\n",
      "tensor(0.4007)\n",
      "tensor(0.4555)\n",
      "tensor(0.4103)\n",
      "tensor(0.4615)\n",
      "第0个EPOCH达到最低的测试LOSS\n",
      "第0个epoch执行时间141.25509524345398s,train loss为0.660750150680542,test loss 为0.721391499042511\n",
      "tensor(0.5533)\n",
      "tensor(0.5520)\n",
      "tensor(0.5411)\n",
      "tensor(0.5486)\n",
      "tensor(0.5591)\n",
      "tensor(0.5035)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# 获取每个batch的训练loss\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m loss_batch \u001b[38;5;241m=\u001b[39m \u001b[43mloss_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# print\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss_batch)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "EPOCH_NUM = 200\n",
    "# 记录最小的测试loss\n",
    "best_test_loss = 100\n",
    "\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    # 获取每一批次图像信息\n",
    "    # 计算整批数据的loss\n",
    "    loss = 0\n",
    "    # 记录一个epoch运行的时间\n",
    "    start_time = time.time()\n",
    "    for i,(x,y) in enumerate(train_loader):\n",
    "        # 每次update清空梯度\n",
    "        model.zero_grad()\n",
    "        # 获取图像\n",
    "        x = x.to(device,dtype=torch.float32)\n",
    "        # 获取标注\n",
    "        y = y.to(device,dtype=torch.float32)\n",
    "        \n",
    "        # 获取预测值\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        # 计算loss\n",
    "        loss_batch = loss_fn(y_pred,y)\n",
    "        \n",
    "        # 计算梯度\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 获取每个batch的训练loss\n",
    "        loss_batch = loss_batch.detach().cpu()\n",
    "        # print\n",
    "        print(loss_batch)\n",
    "        loss+=loss_batch\n",
    "        \n",
    "    # 计算loss\n",
    "    loss = loss / len(train_loader)\n",
    "    # 降低LR：如果loss连续10个epoch不再下降，则降低LR\n",
    "    scheduler.step(loss)\n",
    "\n",
    "    # 计算测试集loss\n",
    "    test_loss = check_test_loss(test_loader,model)\n",
    "    \n",
    "    # 记录到tensorboard可视化\n",
    "    writer.add_scalar('LOSS/train',loss,epoch)\n",
    "    writer.add_scalar('LOSS/test',test_loss,epoch)\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if best_test_loss > test_loss:\n",
    "        # 赋值\n",
    "        best_test_loss = test_loss\n",
    "        # 保存模型\n",
    "        torch.save(model.state_dict(),'saved_model/unet_course_best.pt')\n",
    "        # 输出信息\n",
    "        print('第{}个EPOCH达到最低的测试LOSS'.format(epoch))\n",
    "        \n",
    "    \n",
    "    print('第{}个epoch执行时间{}s,train loss为{},test loss 为{}'.format(\n",
    "        epoch,\n",
    "        time.time() - start_time,\n",
    "        loss,\n",
    "        test_loss\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5da8b5b-70d4-4030-9a19-0c49d36092f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
