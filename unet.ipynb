{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8792ea6b-0167-422f-9f9d-79c90d2aa466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建UNET网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae58161-9d35-4921-8c9e-8d50fb9ff424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa4b84d-fb84-4c69-b94e-05c105c8ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义两次卷积操作\n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.step = torch.nn.Sequential(\n",
    "            # 第一次卷积\n",
    "            torch.nn.Conv2d(in_channels=in_channels,out_channels=out_channels,kernel_size=3,padding=1,stride=1),\n",
    "            # ReLU\n",
    "            torch.nn.ReLU(),\n",
    "            # 第二次卷积\n",
    "            torch.nn.Conv2d(in_channels=out_channels,out_channels=out_channels,kernel_size=3,padding=1,stride=1),\n",
    "            # ReLU\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        return self.step(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2530a777-9514-4513-bc70-00a089aa2221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8af8f691-40dd-43f6-bc0a-da935edf4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模块初始化\n",
    "conv_block = ConvBlock(1,64).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba0ae6a8-d4df-4109-a48d-d566de11b8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]             640\n",
      "              ReLU-2         [-1, 64, 256, 256]               0\n",
      "            Conv2d-3         [-1, 64, 256, 256]          36,928\n",
      "              ReLU-4         [-1, 64, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 37,568\n",
      "Trainable params: 37,568\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 128.00\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 128.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 查看输出大小\n",
    "summary(conv_block,(1,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92d1d409-d54d-4b08-9b69-ad54c2c26aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义UNET网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c56cdd5d-6461-487b-bb62-deb0abfab7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 定义左侧编码器的操作\n",
    "        self.layer1 = ConvBlock(1,64)\n",
    "        self.layer2 = ConvBlock(64,128)\n",
    "        self.layer3 = ConvBlock(128,256)\n",
    "        self.layer4 = ConvBlock(256,512)\n",
    "        \n",
    "        # 定义右侧解码器的操作\n",
    "        self.layer5 = ConvBlock(256+512,256)\n",
    "        self.layer6 = ConvBlock(128+256,128)\n",
    "        self.layer7 = ConvBlock(64+128,64)\n",
    "        \n",
    "        #最后一个卷积\n",
    "        self.layer8  = torch.nn.Conv2d(in_channels=64,out_channels=1,kernel_size=1,padding=0,stride=1)\n",
    "        \n",
    "        # 定一些其他操作\n",
    "        # 池化\n",
    "        self.maxpool = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        #上采样\n",
    "        self.upsample = torch.nn.Upsample(scale_factor=2,mode='bilinear')\n",
    "        # sigmoid\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # 对输入数据进行处理\n",
    "        \n",
    "        # 定义下采样部分\n",
    "        \n",
    "        # input:1X256x256, output: 64x256x256\n",
    "        x1 = self.layer1(x)\n",
    "        # input:64x256x256, output: 64 x 128 x 128\n",
    "        x1_p = self.maxpool(x1)\n",
    "        \n",
    "        # input:  64 x 128 x 128 , output: 128 x 128 x 128\n",
    "        x2 = self.layer2(x1_p)\n",
    "        # input:128 x 128 x 128 , output: 128 x 64 x 64\n",
    "        x2_p = self.maxpool(x2)\n",
    "        \n",
    "        # input: 128 x 64 x 64, output: 256 x 64 x 64\n",
    "        x3 = self.layer3(x2_p)\n",
    "        #input:256 x 64 x 64, output: 256 x 32 x 32\n",
    "        x3_p = self.maxpool(x3)\n",
    "        \n",
    "        #input: 256 x 32 x 32, output: 512 x 32 x 32\n",
    "        x4 = self.layer4(x3_p)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 定义上采样\n",
    "        # input: 512 x 32 x 32，output: 512 x 64 x 64\n",
    "        x5 = self.upsample(x4)\n",
    "        # 拼接,output: 768x 64 x 64\n",
    "        x5 = torch.cat([x5,x3],dim=1)\n",
    "        # input: 768x 64 x 64,output: 256 x 64 x 64\n",
    "        x5 = self.layer5(x5)\n",
    "        \n",
    "        # input: 256 x 64 x 64,output: 256 x 128 x 128\n",
    "        x6  = self.upsample(x5)\n",
    "        # 拼接,output: 384 x 128 x 128\n",
    "        x6 = torch.cat([x6,x2],dim=1)\n",
    "        # input: 384 x 128 x 128, output: 128 x 128 x 128\n",
    "        x6 = self.layer6(x6)\n",
    "        \n",
    "        \n",
    "        # input:128 x 128 x 128, output: 128 x 256 x 256\n",
    "        x7 = self.upsample(x6)\n",
    "        # 拼接, output: 192 x 256 x256\n",
    "        x7 = torch.cat([x7,x1],dim=1)\n",
    "        # input: 192 x 256 x256, output: 64 x 256 x 256\n",
    "        x7 = self.layer7(x7)\n",
    "        \n",
    "        # 最后一次卷积,input: 64 x 256 x 256, output: 1 x 256 x 256\n",
    "        x8 = self.layer8(x7)\n",
    "        \n",
    "        #sigmoid\n",
    "        x9= self.sigmoid(x8)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return x9\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a9ed793-5311-4192-b5f9-df5aae184dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet实例化检查\n",
    "unet = UNet().to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beeccf28-f794-4734-b236-a429ee7978ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]             640\n",
      "              ReLU-2         [-1, 64, 256, 256]               0\n",
      "            Conv2d-3         [-1, 64, 256, 256]          36,928\n",
      "              ReLU-4         [-1, 64, 256, 256]               0\n",
      "         ConvBlock-5         [-1, 64, 256, 256]               0\n",
      "         MaxPool2d-6         [-1, 64, 128, 128]               0\n",
      "            Conv2d-7        [-1, 128, 128, 128]          73,856\n",
      "              ReLU-8        [-1, 128, 128, 128]               0\n",
      "            Conv2d-9        [-1, 128, 128, 128]         147,584\n",
      "             ReLU-10        [-1, 128, 128, 128]               0\n",
      "        ConvBlock-11        [-1, 128, 128, 128]               0\n",
      "        MaxPool2d-12          [-1, 128, 64, 64]               0\n",
      "           Conv2d-13          [-1, 256, 64, 64]         295,168\n",
      "             ReLU-14          [-1, 256, 64, 64]               0\n",
      "           Conv2d-15          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-16          [-1, 256, 64, 64]               0\n",
      "        ConvBlock-17          [-1, 256, 64, 64]               0\n",
      "        MaxPool2d-18          [-1, 256, 32, 32]               0\n",
      "           Conv2d-19          [-1, 512, 32, 32]       1,180,160\n",
      "             ReLU-20          [-1, 512, 32, 32]               0\n",
      "           Conv2d-21          [-1, 512, 32, 32]       2,359,808\n",
      "             ReLU-22          [-1, 512, 32, 32]               0\n",
      "        ConvBlock-23          [-1, 512, 32, 32]               0\n",
      "         Upsample-24          [-1, 512, 64, 64]               0\n",
      "           Conv2d-25          [-1, 256, 64, 64]       1,769,728\n",
      "             ReLU-26          [-1, 256, 64, 64]               0\n",
      "           Conv2d-27          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-28          [-1, 256, 64, 64]               0\n",
      "        ConvBlock-29          [-1, 256, 64, 64]               0\n",
      "         Upsample-30        [-1, 256, 128, 128]               0\n",
      "           Conv2d-31        [-1, 128, 128, 128]         442,496\n",
      "             ReLU-32        [-1, 128, 128, 128]               0\n",
      "           Conv2d-33        [-1, 128, 128, 128]         147,584\n",
      "             ReLU-34        [-1, 128, 128, 128]               0\n",
      "        ConvBlock-35        [-1, 128, 128, 128]               0\n",
      "         Upsample-36        [-1, 128, 256, 256]               0\n",
      "           Conv2d-37         [-1, 64, 256, 256]         110,656\n",
      "             ReLU-38         [-1, 64, 256, 256]               0\n",
      "           Conv2d-39         [-1, 64, 256, 256]          36,928\n",
      "             ReLU-40         [-1, 64, 256, 256]               0\n",
      "        ConvBlock-41         [-1, 64, 256, 256]               0\n",
      "           Conv2d-42          [-1, 1, 256, 256]              65\n",
      "          Sigmoid-43          [-1, 1, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 7,781,761\n",
      "Trainable params: 7,781,761\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 707.00\n",
      "Params size (MB): 29.69\n",
      "Estimated Total Size (MB): 736.94\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\envs\\course_unet_seg\\lib\\site-packages\\torch\\nn\\functional.py:3454: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "summary(unet,(1,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f733fe-a41c-4bb4-a191-dd0c14ad279e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
